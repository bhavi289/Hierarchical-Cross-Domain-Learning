{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1147c73c-66ab-40f7-9af7-00254994df01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train Product Ranker using Spark GBT\n",
    "# Using Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9497e2e-7232-49a0-aeb9-75e611eb162e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier,RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf,struct,col\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.sql.types import IntegerType,FloatType,ArrayType,StringType,MapType,DoubleType\n",
    "\n",
    "sparse_values = udf(lambda v: v.values.tolist(), ArrayType(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d79943a-4f23-446f-86cb-04560d4d2525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_samples = (\n",
    "    spark.read.parquet('stage_2_train.parquet')\n",
    ")\n",
    "test_samples = (\n",
    "    spark.read.parquet('stage_2_test.parquet')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b518731-0d54-4f9c-88a7-74a1ed88b839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: (1000, 800)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[14]: (1000, 800)</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_samples.count(), test_samples.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T07:15:52.872841Z",
     "start_time": "2023-07-19T07:15:52.869521Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0cedf16-5974-440e-a135-92dd4f59a0ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# selected features\n",
    "assemblerInputs = [\n",
    "'product_l2_score',\n",
    "'product_l2_index',\n",
    "'product_l1_score',\n",
    "'product_l1_index',\n",
    "'product_l3_score',\n",
    "'product_l3_index',\n",
    "'rwf'\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "\n",
    "standard_scaler = StandardScaler(inputCol='features',outputCol='scaled')\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"order_flag\", featuresCol=\"features\",maxIter= 40, maxDepth=6)\n",
    "\n",
    "order_flag_prediction_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        assembler,\n",
    "        gbt\n",
    "    ]\n",
    ")\n",
    "\n",
    "product_probability_fit = order_flag_prediction_pipeline.fit(train_samples)\n",
    "\n",
    "product_probability = (\n",
    "    product_probability_fit\n",
    "    .transform(train_samples)\n",
    "    .withColumn(\"pred\", sparse_values(\"probability\"))\n",
    "    .withColumn('predicted_prob', F.col('pred')[1])\n",
    ")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='predicted_prob', labelCol='order_flag', metricName='areaUnderROC')\n",
    "\n",
    "print(\"AUC train data  : \", evaluator.evaluate(product_probability))\n",
    "\n",
    "test_product_probability = (\n",
    "    product_probability_fit\n",
    "    .transform(test_samples)\n",
    "    .withColumn(\"pred\", sparse_values(\"probability\"))\n",
    "    .withColumn('predicted_prob', F.col('pred')[1])\n",
    ")\n",
    "\n",
    "test_evaluator = BinaryClassificationEvaluator(rawPredictionCol='predicted_prob', labelCol='order_flag', metricName='areaUnderROC')\n",
    "\n",
    "print(\"AUC test data  : \", test_evaluator.evaluate(test_product_probability))\n",
    "\n",
    "#Print feature importance\n",
    "feature_importances = product_probability_fit.stages[-1].featureImportances\n",
    "list1 = sorted(list(zip(assemblerInputs, feature_importances)), key=operator.itemgetter(1), reverse=True)\n",
    "for x in list1:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Stage 2: Spark GBT Product Ranker",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
